<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>IT-Sharer &#187; ID3</title>
	<atom:link href="http://wp.hhy/?feed=rss2&#038;tag=id3" rel="self" type="application/rss+xml" />
	<link>http://wp.hhy</link>
	<description>温 润 醇 和    臻 于 至 善</description>
	<lastBuildDate>Fri, 10 Oct 2014 13:53:13 +0000</lastBuildDate>
	<language>zh-CN</language>
		<sy:updatePeriod>hourly</sy:updatePeriod>
		<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=4.0</generator>
	<item>
		<title>决策树系列算法</title>
		<link>http://wp.hhy/?p=15</link>
		<comments>http://wp.hhy/?p=15#comments</comments>
		<pubDate>Sat, 04 Oct 2014 04:49:55 +0000</pubDate>
		<dc:creator><![CDATA[huahuiyou]]></dc:creator>
				<category><![CDATA[数据挖掘]]></category>
		<category><![CDATA[C4.5]]></category>
		<category><![CDATA[CART]]></category>
		<category><![CDATA[ID3]]></category>
		<category><![CDATA[决策树]]></category>

		<guid isPermaLink="false">http://wp.hhy/?p=15</guid>
		<description><![CDATA[ID3算法 ID3算法的核心：用信息增益作为属性选择的标准。 检测所有属性，用信<span class="ellipsis">&#8230;</span><div class="read-more"><a href="http://wp.hhy/?p=15">查阅全文 &#8250;</a></div><!-- end of .read-more -->]]></description>
				<content:encoded><![CDATA[<p>ID3算法
<p>ID3算法的核心：用信息增益作为属性选择的标准。
<p>检测所有属性，用信息增益最大的属性产生决策树的节点，该节点的不同取值建立分支。再对各分支的数据子集调用决策树算法。
<p>直到所有子集仅包含同一类别的数据为止。
<p>缺点：只对小数据集有效，噪声敏感。
<p>信息增益选择属性偏向取值多的属性；
<p>决策树节点的构造：
<p>节点：决策属性名称，决策条件，决策规则，一般采用连续属性离散化去属性值
<p>决策规则判断函数：属于该节点时，往下探查。
<p>ID3算法的思路：算法描述
<p>输入：属性集合，带类别的数据集合
<p>输出决策树：决策树的头结点，见决策树构造
<p>1.从数据集提取类别集合：类别名称，类别数量（每个类别的概率），每个属性的值列表，取值对应每个类别的数量（概率），
<p>2.计算数据集的系统熵：ES，如果ES=0，则该节点为叶子节点，类别为数据集类别
<p><img title="clip_image001" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; padding-top: 0px; padding-left: 0px; border-left: 0px; display: inline; padding-right: 0px" border="0" alt="clip_image001" src="http://wp.hhy/wp-content/uploads/2014/10/clip_image001.png" width="244" height="18">
<p>：用概率乘以概率的对数，再每个类别相减。
<p>3.对于每一个属性A，计算信息熵EA
<p>3.1对于每一个取值AV，计算该取值的信息熵EAV：对应每个类别均有概率，用2方法计算信息熵，Pn代表该取值对应的属于类别n的概率。
<p>3.2加权平均属性A的所有取值的信息熵，EA=∑权重（A属性取该值的概率）*该值的EAV
<p>4.求信息增益：EAZ=ES-EA；在所有属性中取信息增益最大的作为决策节点，该节点的不同取值作为分支。
<p>5.递归建立分支节点：对于A=V，选择对应的数据子集，剔除A属性，对该数据集采用ID3算法，
<p>6.返回4中建立的头结点。
<p>ID3分类思路：算法描述
<p>输入： ID3决策树，分类样本。
<p>输出：分类标签
<p>1.如果ID头结点是叶子节点，返回分类标签的值。
<p>2.读取头结点属性标签，以及分类样本对应属性值
<p>3.根据对应属性值，查找对应的分支。
<p>4.递归调用ID3分类函数，输入分支树、待分类样本。
<p>5.return 递归返回值。
<p>参考资料：
<p><a href="http://blog.csdn.net/guoqiangma/article/details/7188678">http://blog.csdn.net/guoqiangma/article/details/7188678</a>
<p><a href="http://www.cnblogs.com/zhangchaoyang/articles/2196631.html">http://www.cnblogs.com/zhangchaoyang/articles/2196631.html</a>
<p><a href="http://czhsuccess.iteye.com/blog/1864652">http://czhsuccess.iteye.com/blog/1864652</a>
<p>机器学习十大算法（1）C4.5
<p>一、原理
<p>对ID3算法的改进：
<p>1.用信息增益率来选择属性；熵的变化值：把每个属性看成是类别，用信息熵公式计算信息熵HV（同ID3中的第二步），然后用ID3中的信息增益除以HV，得到信息增益率。和ID3中第3步方法不同，不考虑属性值对应类别的熵，只是属性一个维度的熵。
<p>2.决策树构造过程中，进行剪枝，考虑样本少的节点，会产生过拟合问题。
<p>3.可以处理离散型数据。
<p>4.对不完整数据进行处理。
<p>连续属性的处理：
<p>在选择某节点的分支属性时，对于离散型属性，按ID3的算法算增益，然后再算增益率。
<p>对于连续型的属性，则需要对其进行离散化处理：
<p>1.将连续属性值从小到大排序：AV1，AV2,…AVN
<p>2.对1序列可以分成N-1个分割点，也就是有N-1种划分成2份的方法。
<p>3.在N-1种分割方法中寻找一种最佳分割：按C4.5信息增益率计算出N-1中分割的信息增益率，取最大的那个作为该属性的分割，和信息增益率。
<p>后剪枝处理：
<p>避免树的高度无节制增长，避免过度拟合数据。
<p>估计剪枝前后的误差，决定是否剪枝。
<p>Pr[ (−)/( (1−)/) &gt;]= c
<p>其中N是实例的数量，f=E/N为观察到的误差率（其中E为N个实例中分类错误的个数），q为真实的误差率，c为置信度（C4.5算法的一个熟人参数，默认值为0.25），z为对应于置信度c的标准差，其值可根据c的设定值通过查正态分布表得到。
<p>通过上公式可以计算出真实误差率q的一个置信区间上限，用此上限为该节点误差率e做一个悲观的估计：
<p><img title="clip_image002" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; padding-top: 0px; padding-left: 0px; border-left: 0px; display: inline; padding-right: 0px" border="0" alt="clip_image002" src="http://wp.hhy/wp-content/uploads/2014/10/clip_image002.png" width="223" height="106">
<p>根据剪枝前后e的值，从而决定是否需要剪枝。
<p>缺失值的处理：
<p>针对数据缺少某些属性值的情况。
<p>策略一：对于赋予该值为该属性常见的值。
<p>根据一个概率分配所有缺少该属性值的样本一个属性值，使得该属性值分布和之前一致。
<p>C4.5生成算法：
<p>输入：数据集DataSet
<p>输出：决策树根节点
<p>1.创建根节点N
<p>2.计算类别的信息熵，同ID3算法：统计类别标签序列以及属性值序列，&lt;属性值，类别&gt;序列的数量，对于属性值缺失的地方，采用策略一或者策略二进行补充。
<p>3.如果信息熵为0，则设置节点为叶子节点，类别为数据集类别。
<p>4.对于每个属性，计算增益率
<p>4.1如果属性是离散属性，则按ID3算法计算增益，按类别信息熵计算方法计算属性信息熵。最终得到增益率
<p>4.2如果属性是连续属性，则将属性值从小到大排序，N个不同的属性值。
<p>4.2.1在N-1个位置分别将属性分成两部分，离散的属性值。
<p>4.2.2按4.1的方法计算信息增益率。
<p>4.2.3取最大的信息增益率和划分位置，作为该属性的信息增益率。
<p>附：
<p>5.在所有属性增益率中选择最大增益率的属性，作为根节点的属性标签。属性值作为分支条件。
<p>6.递归下一个节点：根据每个属性值构建分支节点，属性值满足对应分支条件的数据当中输入踢去根节点属性的数据集。
<p>7.计算每个节点的分类错误，进行剪枝。？？？剪枝后如何处理
<p>8.return 根节点
<p>C4.5分类算法：同ID3
<p>参考资料：
<p><a href="http://blog.csdn.net/xuxurui007/article/details/18045943">http://blog.csdn.net/xuxurui007/article/details/18045943</a>
<p><a href="http://www.cnblogs.com/zhangchaoyang/articles/2842490.html">http://www.cnblogs.com/zhangchaoyang/articles/2842490.html</a>
<p><a href="http://wenku.baidu.com/link?url=G7mc7ywnFgAc62PAIVkSqVHbS3TRYrN0rI-q8tspmgnDFGRngeoKCM_FPL31s9K7G4RoA45fZzeFNyube_LzhZfrkjY8XO41MkiINtyZqfa">http://wenku.baidu.com/link?url=G7mc7ywnFgAc62PAIVkSqVHbS3TRYrN0rI-q8tspmgnDFGRngeoKCM_FPL31s9K7G4RoA45fZzeFNyube_LzhZfrkjY8XO41MkiINtyZqfa</a>
<p>weka.classifiers.trees.j48
<p>机器学习十大算法（10）CART
<p>Classification and regression trees
<p>特点:采用二分递归分割技术，将当前样本分成两个子集，使得生成的每个非叶子节点都有两个分支。二叉树。
<p>针对离散属性进行分类，针对连续属性则进行回归。
<p>数据划分策略：Gini指标
<p><img title="clip_image003" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; padding-top: 0px; padding-left: 0px; border-left: 0px; display: inline; padding-right: 0px" border="0" alt="clip_image003" src="http://wp.hhy/wp-content/uploads/2014/10/clip_image003.gif" width="177" height="49">
<p>计算方式：
<p>对于每一个属性，划分成两部分，每部分数据中，计算Gini指标，然后用加权平均两部分的GinI指标作为该属性的Gini指标。权值为该部分数据所占的比例。
<p>在所有属性中选择属性Gini指标最小的一个作为决策节点，由此数据集被分成较纯的两部分。
<p>关键：根据属性值，划分成两部分，这个真子集比较难选，2^N种可能。
<p>有个问题：如果一个属性中的两个值的区别是区分某两个或两类样本的关键，在该属性的二元划分中没有将其划分开来，那怎么办？
<p>参考资料：
<p><a href="http://blog.csdn.net/hewei0241/article/details/8280490">http://blog.csdn.net/hewei0241/article/details/8280490</a>
<p><a href="http://blog.sina.com.cn/s/blog_7399ad1f01014oic.html">http://blog.sina.com.cn/s/blog_7399ad1f01014oic.html</a></p>
]]></content:encoded>
			<wfw:commentRss>http://wp.hhy/?feed=rss2&#038;p=15</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
	</channel>
</rss>
